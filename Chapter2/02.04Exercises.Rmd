---
title: "" 
author: "R.Liddell" 
output: 
  word_document: 
  toc: TRUE
editor_options: 
  markdown: 
    wrap: 72
---

1.  **For each of parts (a) through (d), indicate whether we would
    generally expect the performance of a flexible statistical learning
    method to be better or worse than an inflexible method. Justify your
    answer.**


a.  **The sample size n is extremely large, and the number of predictors
    p is small.** 
    
    Flexible, with a large sample size and few predictors
    the flexible method leverages the most from the data.

b.  **The number of predictors p is extremely large, and the number of
    observations n is small.** 
    
    Inflexible. In this case there is not
    much data to help support a highly flexible models. The inflexible
    model reduces the tendency to overfit in this situation.

c.  **The relationship between the predictors and response is highly
    non-linear.** 
    
    Flexible. The non-flexible model will try to impose a
    linear relationship on the known highly non-linear data.

d.  **The variance of the error terms, i.e. σ2 = Var(ϵ), is extremely
    high.** 
    
    Non-flexible. Flexible models exacerbate issues with
    variability which is minimized by non-flexible models less affected
    by variability in data


2.  **Explain whether each scenario is a classification or regression
    problem, and indicate whether we are most interested in inference or
    prediction. Finally, provide n and p.**


a.  **We collect a set of data on the top 500 firms in the US. For each
    firm we record profit, number of employees, industry and the CEO
    salary. We are interested in understanding which factors affect CEO
    salary.**

    This is a regression problem where we are interested in being able
    to infer the factors affecting CEO Salary with little need to make
    predictions. (n=500, p=3)

b.  **We are considering launching a new product and wish to know
    whether it will be a success or a failure. We collect data on 20
    similar products that were previously launched. For each product we
    have recorded whether it was a success or failure, price charged for
    the product, marketing budget, competition price, and ten other
    variables.**

    This is a classification problem with the main goal being able to
    predict if a product with be a success or failure. (n=20,p=13)

c.  **We are interested in predicting the % change in the USD/Euro
    exchange rate in relation to the weekly changes in the world stock
    markets. Hence we collect weekly data for all of 2012. For each week
    we record the % change in the USD/Euro, the % change in the US
    market, the % change in the British market, and the % change in the
    German market.**

    This is a regression problem with the goal of prediciting thew
    weekly change in stock market. (n=51,p=4)
    
3.  **We now revisit the bias-variance decomposition.**

a.  **Provide a sketch of typical (squared) bias, variance, training error,
    test error, and Bayes (or irreducible) error curves, on a single plot,
    as we go from less flexible statistical learning methods towards more
    flexible approaches. The x-axis should represent the amount of flexibility
    in the method, and the y-axis should represent the values for each
    curve. There should be five curves. Make sure to label each one.**
    
    ```{r}
    
    college <- ISLR2::College
    summary(college)
    pairs(college[,1:10])
    plot(college$Private,college$Outstate)
    college$Elite <- ifelse(college$Top10perc>50,"Yes","No")|>
      as.factor()
    summary(college['Elite'])
    plot(college$Elite,college$Outstate)
    par(mfrow=c(2,2))
    hist(college$Top10perc)
    hist(college$Top25perc)
    hist(college$F.Undergrad)
    hist(college$P.Undergrad)
    
    ```

```{r}
auto <- ISLR2::Auto
auto$origin <- factor(auto$origin)
summary(auto)
lapply(auto[,c(1:7)],sd)
```

```{r}
lapply(c(1:7),function(x) {scatter.smooth(auto$mpg,auto[,x],lpars=list(col='red',lwd=1))})
```


```{r}
summary(auto[-c(10:85)])
lapply(auto[-c(10:85),c(1:7)],sd)
```